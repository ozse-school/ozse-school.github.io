import React from "react";

const programData = {
  day1: {
    date: "Feb 09, 2026",
    sessions: [
      { time: "09:00-09:10", duration: "10", type: "", title: "Arrival - Check-in", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "The Future of OzSE", speaker: "", abstract: "", bio: "" },
      { time: "09:10-09:20", duration: "10", type: "Opening", title: "Welcome & House Keeping", speaker: "OC Team", abstract: "", bio: "" },
      { time: "09:20-09:40", duration: "20", type: "Talk", title: "Revisiting Human Values in SE in an AI World", speaker: "Prof Jon Whittle (ex-CSIRO)", abstract: "In 2017, a team of researchers at Monash University successfully grew a body of research on human values in software engineering. The premise was that for systems to be more inclusive, to respect diversity, to be sustainable, and to generally have a more positive impact on society, we needed to adapt software engineering methods to make human values first class citizens. With the rise of AI, I will reflect on this body of work and ask the key question whether AI presents a unique opportunity to ensure our software systems have human values built in, leading to systems that better serve humanity and help humans make better decisions about how to design software.", bio: "Professor Jon Whittle is Australia's leading thought leader on AI for business. A former technical lead at NASA and director of CSIRO's AI capability, he also founded Australia's National AI Centre. He has a global reputation for applying AI to achieve real world impact with a human-centred approach, having worked with or advised Boeing, the Federal Aviation Administration in the US, Google, Microsoft, NASA, Australian Super, Supreme Court Justice of Victoria, state and federal governments. He has worked extensively in the US, the UK, UAE, Germany and Australia. He is author of two books on AI: Responsible AI - Best Practices for Creating Trustworthy AI Systems, and AI for Business - A Guide to AI Adoption. He also hosts the award winning podcast, CSIRO Presents Everyday AI, and writes a Substack, Being Human in an AI World. He regularly appears in the media, having recently been interviewed for ABC Radio, The Age, Sydney Morning Herald, The AFR, Sky TV and ABC TV." },
      { time: "09:40-10:00", duration: "20", type: "Talk", title: "Securing Packages Built From Open Source", speaker: "A/Prof Jens Dietrich (Wellington)", abstract: "Over the past few years, software engineering has been transformed by the large-scale reuse of components and the growing automation of development processes. These changes have unlocked significant efficiencies, but they've also introduced new security risks. Today's software supply chain attacks target not only the commodity components we depend on, but also the automated pipelines that assemble them. Incidents like Equifax, SolarWinds, and Log4Shell have caused widespread economic and social harm. A particular problem are attacks based on the famous Ken Thompson hack, where a compromised compiler (or more general, a compromised build) can produce insecure binaries from secure source code. Incidents like SolarWinds, XCodeGhost and XZ follow this general pattern. To address this particular issue, several companies including Google, Oracle and RedHat are now independently building packages from open source at scale, and provide them to their customers. Surprisingly, often those packages are different from the original packages built by developers. In this talk, I will discuss some of the work by us and others on reproducible and alternative builds. I will present DALEQ, a tool we have developed that compares binaries by soundly under-approximating (undecidable) behavioural equality.", bio: "" },
      { time: "10:00-10:20", duration: "20", type: "Talk", title: "From RAISE to Risk-Ready: Architecting Functional Safety for Citizen AI Agent Makers", speaker: "Dr. Joey Chua (Transurban)", abstract: "The increasing decentralization of enterprise AI, moving from specialist-led development to a landscape of \"Citizen AI Agent Makers,\" necessitates a fundamental re-evaluation of traditional software engineering. This strategic shift is crucial both for realizing the benefits of AI democratization and for preventing a collapse in AI governance. This talk will address the challenges of transitioning from foundational Responsible AI Software Engineering (RAISE) capabilities to a robust functional safety framework tailored for low-code, autonomous environments. Key AI engineering practicesâ€”such as \"PromptOps,\" identity-centric governance, and \"AI-testing-AI\" regression suitesâ€”must be simplified and made accessible to business users. This will enable them to create and share autonomous agents securely within defined safety envelopes. To empower non-technical staff to innovate safely and responsibly, academics and practitioners must pivot away from reliance on manual oversight. The focus must shift toward developing automated safety scorecards and alignment indices.", bio: "Dr Joey (Joselito) Chua is Head of AI Engineering and Operations at Transurban, where he leads the core team developing innovative technologies that help get people where they want to go as quickly and safely as possible. He has almost two decades of experience delivering AI/ML-enabled solutions in a diverse range of industries, including transport, distributed energy resources, strategic pricing, behavioural insights, market intelligence, cyber security, bioinformatics, environmental management, decision policy frameworks, economic modelling and process design. He earned his Masters and PhD degrees in Computer Science at Monash University." },
      { time: "10:20-10:30", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "10:30-11:00", duration: "30", type: "Break", title: "â˜• Break", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "When Neuro-Symbolic AI Meets Software Engineering", speaker: "", abstract: "", bio: "" },
      { time: "11:00-11:20", duration: "20", type: "Talk", title: "Towards Verifiable Autonomous Systems with NeuroSymbolic Reasoning", speaker: "A/Prof James Zheng (Macquarie)", abstract: "Learning-enabled autonomous systemsâ€”such as self-driving vehicles and intelligent dronesâ€”pose unprecedented challenges for safety assurance due to the opaque and unpredictable nature of deep neural networks. This talk introduces NeuroStrata, a new neurosymbolic architecture for autonomous systems, which marks a paradigm shift from black-box learning to interpretable, reasoning-based intelligence. By integrating neural perception with symbolic reasoning, NeuroStrata enables certifiable AI, bridging the gap between data-driven adaptability and formal verifiability. This vision is now being realized through a neurosymbolic perception module deployed in collaboration with an Australian drone company, demonstrating real-world feasibility for safety-critical applications.", bio: "A/Prof. Xi Zheng (Macquarie University, Australia) is an ARC Future Fellow (2024â€“2028) whose research focuses on testing and verification of learning-enabled cyber-physical systems, with applications to autonomous vehicles and UAVs. He has secured over $2.4M in competitive funding and published extensively in top venues such as ICSE, FSE, and TSE. His research outputs have been adopted in industry by partners including Ant Group and UAV companies. Beyond research, he has taken on significant leadership and service roles, serving as TPC Chair (MobiQuitous 2026), OC/TPC member (ICSE 2026, FSE 2026, PerCom 2026, CAV 2025). He also co-founded the TACPS workshop series and is co-organizer of the Shonan Seminar #235 and Dagstuhl Seminar 202501048 (2026) on neurosymbolic AI and LLMs for reliable autonomous systems." },
      { time: "11:20-11:40", duration: "20", type: "Talk", title: "Static Analysis from Code to AI Models", speaker: "A/Prof Yulei Sui (UNSW)", abstract: "Static analysis has long served as an important basis for program understanding and reasoning, enabling the extraction and interpretation of abstract representations of software systems. This talk explores how the principles of static analysis, as developed in our SVF framework, can be extended beyond traditional code analysis to areas such as abstract execution of AI models. As part of this ongoing effort, we are developing the ACT tool, which applies static reasoning and testing of neural networks. It builds on the shared foundations between program analysis and neural network verification, both grounded in abstraction and symbolic reasoning over large input spaces. Our early findings indicate that static reasoning techniques provide useful insights for improving the reliability and robustness of modern AI systems.", bio: "Yulei Sui is an Associate Professor at UNSW. His research focuses on software analysis and verification, with an emphasis on developing open-source frameworks for static analysis to improve the reliability and quality of software systems. He also studies the intersection of large language models and software verification. His work has been published in conferences and journals in program analysis and software engineering, and has received recognition through paper awards at ICSE, FSE, OOPSLA, SAS, and CGO. His research has been supported by an ARC Future Fellowship, ARC Discovery Projects, a JSPS Fellowship, and industry funding from Google and Amazon." },
      { time: "11:40-12:00", duration: "20", type: "Talk", title: "AI for DevSecOps (tentative)", speaker: "Dr. Cristina Cifuentes (Oracle)", abstract: "", bio: "Cristina is the Vice President of the Oracle Software Assurance organisation where she leads a team of security researchers and software and machine learning engineers to make application security and software assurance, at scale, a reality. She was the founding Director of Oracle Labs Australia in 2010, where she led a team of researchers and engineers for close to 12 years, with a focus on scaling up Program Analysis techniques in new application security tools. Cristina led and successfully released Oracle Parfait, a static analysis tool used by thousands of C, C++ and Java developers each day. Cristina's passion for tackling the big issues in the field of Program Analysis began with her PhD work in binary decompilation at the Queensland University of Technology, which led to her being named the Mother of Decompilation for her pioneering contributions to this domain.\n\nBefore she joined Oracle and Sun Microsystems, Cristina held academic posts at major Australian Universities, co-edited Going Digital, a landmark book on Cybersecurity, and served on the executive committees of ACM SIGPLAN and IEEE Reverse Engineering. She holds 20+ US patents and over 50 peer-reviewed publications, and has given Keynotes at international Computer Science conferences. Where possible, she channels her interests into mentoring young programmers and minorities in STEM." },
      { time: "12:00-12:10", duration: "10", type: "Spotlight", title: "Supercharge Compiler Engineering with LLMs", speaker: "Dr. Yongqiang Tian (Monash)", abstract: "The field of compiler engineering has long relied on deep human expertise and painstaking manual effort for tasks like finding subtle bugs or optimizing performance. This labour-intensive process, however, fundamentally limits the pace of development and analysis. This talk presents our recent work on how Large Language Models (LLMs) can fundamentally supercharge this process, allowing engineers to operate with unprecedented speed and efficiency. We will demonstrate how LLMs can intelligently (1) generate candidates for missed peephole optimizations and (2) implement language-specific transformations to automate the debugging workflow.", bio: "Dr. Yongqiang Tian is an Assistant Professor at Monash University. He holds a dual Ph.D. from the University of Waterloo and the Hong Kong University of Science and Technology. His research lies in the areas of software testing and debugging, with a particular focus on compilers and deep learning systems. The proposed techniques have uncovered over 200 bugs in widely used software systems, including GCC, LLVM, and TVM. His work has been published in leading peer-reviewed journals and conferences such as TOSEM, ICSE, ASPLOS, FSE, ASE, ISSTA, EmSE, and IJCAI. His research has received support from prominent funding agencies and industry partners, including Microsoft and Cisco. He also contributes actively to the research community, serving as the SIGSOFT Information Director, a reviewer, and a program committee member for several top-tier conferences and journals." },
      { time: "12:10-12:20", duration: "10", type: "Spotlight", title: "Static Analysis-Inspired Automated Program Repair Using AI", speaker: "Sumudu Bambarawana Liyanage (Otago)", abstract: "Static analysis tools are widely used in software development to detect bugs during the development phase. However, they often generate a large number of warnings, and manually addressing these warnings can be time-consuming and may not always yield optimal fixes. Automated Program Repair (APR) tools for static analysis warnings offer a promising solution, but existing approaches have limitations. Many are not thoroughly evaluated, raising concerns about their reliability, and their suggested fixes often lack contextual awareness. Furthermore, most rely on traditional, template-based methods that may fail to capture the complexity of real-world software systems. In this research, we propose an AI-driven APR approach that addresses these challenges comprehensively. Unlike existing solutions that apply AI to only a single phase of the fault detection and repair pipeline, our approach leverages AI across the entire APR pipelineâ€”defect identification, localization, patch generation, and validationâ€”aiming to produce more reliable and context-aware repairs for static analysis warnings.", bio: "" },
      { time: "12:20-12:30", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "12:30-13:30", duration: "60", type: "Lunch", title: "ðŸ½ï¸ Lunch", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "Enhancing the Quality of LLM Code Generation", speaker: "", abstract: "", bio: "" },
      { time: "13:30-13:50", duration: "20", type: "Talk", title: "Enhancing LLM Code Generation with Ensembles: A Similarity-based Selection Approach", speaker: "Dr. Guowei Yang (Queensland)", abstract: "Abstract placeholder - to be filled", bio: "Bio placeholder - to be filled" },
      { time: "13:50-14:00", duration: "10", type: "Spotlight", title: "Hallucinations in Code Change to Natural Language Generation", speaker: "Dr Chunhua Liu (UniMelb)", abstract: "Language models have shown strong capabilities across a wide range of tasks in software engineering, such as code generation, yet they suffer from hallucinations. While hallucinations have been studied independently in natural language and code generation, their occurrence in tasks involving code changes which have a structurally complex and context-dependent format of code remains largely unexplored. This talk will present the first comprehensive analysis of hallucinations in two critical tasks involving code change to natural language generation: commit message generation and code review comment generation. We quantify the prevalence of hallucinations in recent language models and explore a range of metric-based approaches to automatically detect them. Our findings reveal that approximately 50% of generated code reviews and 20% of generated commit messages contain hallucinations. Whilst commonly used metrics are weak detectors on their own, combining multiple metrics substantially improves performance. Notably, model confidence and feature attribution metrics effectively contribute to hallucination detection, showing promise for inference-time detection.", bio: "Dr Chunhua Liu is a Research Fellow in Natural Language Processing (NLP) in the School of Computing and Information Systems at the University of Melbourne. Her research interests primarily sit at the intersection of human-centred communication and NLP: she studies how people understand concepts and encode commonsense and cultural knowledge, examines how NLP models represent and learn such knowledge, and explores these models' capabilities in persuasion and disinformation. At the intersection of NLP and software engineering, her research integrates NLP techniques to improve software development processes, with a focus on automating the code-review process to reduce the time and effort required for manual reviews. Her recent work emphasizes the importance of high-quality datasets by detecting noisy and hallucinated code-review comments to ensure the reliability and trustworthiness of AI systems in software engineering." },
      { time: "14:00-14:10", duration: "10", type: "Spotlight", title: "Explainable Multi-Agent Systems for Code Quality Prediction (XMAS-CQP)", speaker: "Lei Pei (Otago)", abstract: "Advances in generative AI have accelerated software development, yet ensuring code quality and reliability remains a major challenge for both academia and industry. This talk presents XMAS-CQP, an explainable multi-agent system designed to predict, assess, and interpret software quality risks. Our approach integrates specialised LLM-powered agentsâ€”such as code analysis, risk assessment, and explanation agentsâ€”working collaboratively to evaluate code from multiple perspectives. We incorporate explainable AI techniques to generate human-understandable rationales, enabling developers to trace how predictions are made and why potential issues emerge. Early experiments demonstrate improved interpretability and prediction consistency compared with single-agent or black-box LLM approaches. This work contributes towards responsible AI-embedded software engineering, offering transparent, auditable, and collaborative tooling for future development pipelines.", bio: "" },
      { time: "14:10-14:20", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "14:20-15:00", duration: "40", type: "Activity", title: "AI Tutorial: Building AI Assistants with LangChain and LangGraph", speaker: "Dr. Naim Rastgoo (Monash)", abstract: "Abstract placeholder - to be filled", bio: "Bio placeholder - to be filled" },
      { time: "15:00-15:30", duration: "30", type: "Break", title: "â˜• Break", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "Software Requirement and Evolution in the Age of Generative AI", speaker: "", abstract: "", bio: "" },
      { time: "15:30-15:50", duration: "20", type: "Talk", title: "Prompt Engineering, LLMs and RAG for effective Requirements driven Software Quality Assurance", speaker: "Dr. Chetan Arora", abstract: "This session explores how Prompt Engineering, Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) can transform requirements-driven software quality assurance. We'll look at how to turn natural-language requirements into precise test scenarios, use LLMs to automatically generate and refine test artifacts, and apply RAG to ground QA analysis in the latest specifications and domain knowledge. We'll also cover different prompt engineering techniques in RE.", bio: "Dr Chetan Arora is a senior lecturer in software engineering at Monash University. Dr Arora is passionate about requirements engineering, software quality assurance, and applied AI research. He has extensive experience in industry and academia, with a focus on responsible AI, trustworthy AI-driven systems, and compliance in software development. His work spans various domains, including space systems, healthcare, finance and legal information systems. He has played a key role in bridging industry and academia through applied research initiatives, with several research outcomes adopted in practice. Dr Arora has won several best paper awards for his work" },
      { time: "15:50-16:10", duration: "20", type: "Talk", title: "Human-Oriented SE in the age of GenAI", speaker: "Dr. Maria Spichkova", abstract: "This talk focuses on the impact of GenAI on the Human-oriented Software Engineering (SE). Software systems are developed by humans and for humans. However, human factors, cultural and social diversity aspects are not always taken into account, which has a negative impact on usability and sustainability, as well as on the success of innovative solutions. On the other hand, software systems have a large impact on society and culture. With each passing decade, this impact becomes increasingly stronger, as more tasks are performed using software solutions. This makes socio-cultural factors increasingly important when analysing both software development processes (especially in Agile/Scrum settings) and the software features provided to end-users. The rise of AI means changes in SE approaches, and it's crucial to ensure that these changes consider human-related aspects.", bio: "Dr Maria Spichkova is a Senior Lecturer in Software Engineering at RMIT University. Her research interests include human aspects of software engineering (SE), requirements engineering, the application of AI in SE, computer science education, formal methods, and sustainability. Dr Spichkova received her PhD from the Technical University of Munich (Germany), where she worked as a researcher and lecturer between 2003 and 2013. She has served as an OC and PC member for various top-ranked conferences and leading journals, such as TOSEM, JSS, ICSE, RE, ICSA, MODELS, and ECSA, and has also organised several workshops and special sessions at ECSA, RE, SEFM, and ENASE. Dr Spichkova has won several teaching awards for her contributions to SE education." },
      { time: "16:10-16:20", duration: "10", type: "Spotlight", title: "Human-centric Requirements in Aged care Digital Health Software", speaker: "Yuqing Xiao", abstract: "We conducted a systematic review of the literature on requirements engineering (RE) for older adult digital health software to establish the current state of understanding of the needs of older adults in aged care digital health. Following established guidelines, we developed a protocol and systematically searched eight databases, resulting in 69 highly relevant primary studies. These studies underwent structured data extraction, synthesis, and reporting to map existing knowledge and practices. Complementing this, we carried out an empirical survey involving developers, caregivers, and older adults to identify functional and non-functional requirements, capture stakeholder perspectives, and uncover current limitations and future visions. Together, these findings provide an integrated evidence base to guide the design and development of digital health solutions tailored to older adults in aged care.", bio: "Yuqing Xiao is a Doctoral Candidate in IT at Monash University, passionate about advancing aged care through digital health. With nine years of combined research and industry experience, Yuqing's current research focuses on Software Engineering for Digital Health, with a particular emphasis on requirements for Digital Aged Care. Her work explores human-centric requirements engineering for older adults and improving user experience in digital health applications." },
      { time: "16:20-16:30", duration: "10", type: "Spotlight", title: "Motivations Matter: Personalizing Open Source Project Recommendations", speaker: "Shashiwadana Nirmani", abstract: "Open source software (OSS) thrives on diverse contributors, yet many practitioners struggle to find projects that truly fit their motivations. In our study with 208 OSS practitioners, we uncovered how demographics such as age, gender, and roles shape contributors' motivations, and how these motivations, in turn, influence their preferences for project characteristics like development stage, documentation, and community practices. Distinguishing newcomers from experienced contributors revealed unique patterns. Building on these findings, I developed a prototype recommendation system that integrates human factors alongside technical ones. By aligning project recommendations with contributors' motivations and backgrounds, the prototype demonstrates how motivation-aware recommendations can improve onboarding, sustain engagement, and strengthen OSS ecosystems. Further, I would like to highlight current gaps in motivation-aware OSS project recommendation systems and outlining future directions to advance this research area.", bio: "Shashiwadana Nirmani is a PhD candidate in Software Engineering at Deakin University, Australia. Her research focuses on enhancing the recommendation of open source software projects to contributors based on human factors. Her research interests include software engineering, open source software development, and human factors." },
      { time: "16:30-16:40", duration: "10", type: "Spotlight", title: "Towards Automated Documentation Maintenance in Rapidly Evolving Software Ecosystems", speaker: "Haoyu Gao", abstract: "Software documentation is a critical artefact for developers, yet it frequently suffers from a significant issue: being outdated. In our previous research, we performed large-scale empirical studies on README update patterns and their triggers, leading us to propose a maintenance template that proved useful for both users and maintainers. However, templates alone cannot solve the problem. In this new research, we propose an LLM-based agentic system to automate documentation update behaviour within the pull request context, incorporating a human-in-the-loop. Our methodology and findings are threefold: We designed and evaluated the LLM-based agentic system, with quantitative analysis of each component verifying its design and revealing a promising direction for automated documentation maintenance. A qualitative analysis of model failure cases uncovers pitfalls in current maintenance paradigms and shows clear directions for improving our pipeline. We conducted two case studies with open-source software developers to understand the perceived helpfulness of the information our tool provides, validating its practical utility.", bio: "Haoyu's research focuses on supporting developers in documentation maintenance and knowledge acquisition in both traditional and AI-based software systems. He is particular interested in using qualitative methods to empirically understand issues and phenomenons in the software ecosystems from the lens of both software artefacts and developers, as well as building automated pipelines using machine learning methods." },
      { time: "16:40-16:50", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "16:50-17:00", duration: "10", type: "Closing", title: "Wrap-Up of the Day", speaker: "OC Team", abstract: "", bio: "" },
    ]
  },
  day2: {
    date: "Feb 10, 2026",
    sessions: [
      { time: "", duration: "", type: "Section", title: "Enhancing Trustworthy of Agentic AI Systems", speaker: "", abstract: "", bio: "" },
      { time: "09:00-09:20", duration: "20", type: "Talk", title: "Verifiability-First AI Engineering: Building Trust in AIware-Centric Systems", speaker: "Dr. Qinghua Lu (CSIRO)", abstract: "As AI systems evolve from software-centric architectures to AIware-centric ecosystems, the fundamental engineering challenge is shifting from producing behavior to verifying it. Traditional software engineering assumes that business logic resides in human-written code, enabling specification, implementation, and verification through deterministic tests and analysis. In contrast, foundation models and agentic systems embed logic in model weights and learned policies, introducing unprecedented complexity in assurance. This talk argues that verifiability must become the core principle of AI engineering. We will explore design strategies such as decomposing tasks into machine/human-verifiable components, embedding constraints into pipelines, leveraging formal methods and automated testing, and extending verification beyond correctness to include alignment, interpretability, and safety. As AI takes over coding and testing loops, human roles shift toward strategic oversight, constraint design, and verification orchestration. This talk outlines emerging patterns for architecture, assurance, and governance in AIware-centric systems, and how verifiability will define the next decade of AI engineering.", bio: "Qinghua Lu is the Acting Research Director of Software and Computational Systems (SCS) Research Program at CSIRO, specialising in AI engineering and responsible AI. She was the winner of Asia-Pacific Women in AI Trailblazer Award in 2023. She is the lead author of the world's first practitioner-focused Responsible AI book, Responsible AI: Best Practices for Creating Trustworthy AI Systems, which reached #3 Amazon's AI best-seller, and the co-author of Engineering AI Systems: Architecture and DevOps Essentials. Her Responsible AI Pattern Catalogue has been adopted by Australia's National AI Centre Digital Pathways and the National Framework for the Assurance of AI in Government, and is widely used by industry to improve AI products or assess AI frameworks. She has led/co-led major national AI initiatives, including Australia's Voluntary AI Safety Standards and Department of Industry's General-Purpose AI Risk Assessment Methodology. Internationally, she represents Australia in key international AI safety initiatives, including the Frontier Model Forum." },
      { time: "09:20-09:40", duration: "20", type: "Talk", title: "Metamorphic Testing for LLMs: Improving Trust and Quality in AI", speaker: "Dr. Valerio Terragni (Auckland)", abstract: "Large Language Models (LLMs) have become central to modern Natural Language Processing (NLP), powering applications from text generation to question answering. Despite their impressive performance, LLMs can produce incorrect or inconsistent outputs, raising concerns about reliability. Detecting these faulty behaviors in absence of labeled data is challenging due to the oracle problem. Metamorphic Testing (MT) offers a promising solution by leveraging Metamorphic Relations (MRs), which define expected relationships between outputs of related inputs, enabling fault detection without explicit oracles. This talk introduces the core principles of Metamorphic Testing and discusses its relevance for testing AI systems. It will then present our recent work, the most comprehensive study of MT for LLMs to date. We reviewed the literature and identified 191 MRs for NLP tasks, implementing 36 representative MRs to run over 560,000 metamorphic tests on three popular LLMs. Our findings reveal both the strengths and limitations of MT in improving LLM reliability and highlight future research directions for SE4AI and AI4SE.", bio: "Valerio Terragni is a Senior Lecturer in Software Engineering at the University of Auckland and Program Director of the Bachelor of Engineering in Software Engineering since 2024. His research focuses on software testing, with extensive work on test input and oracle generation. He has contributed to areas such as automated test generation, search-based software engineering, and metamorphic testing. More recently, his work addresses the challenges of testing Machine Learning and AI systems (SE4AI) and leverages AI techniques, including Large Language Models, to advance software engineering (AI4SE)." },
      { time: "09:40-10:00", duration: "20", type: "Talk", title: "Trustworthy AI Agents for Software Engineering", speaker: "Prof. Aldeida Aleti (Monash)", abstract: "Large Language Models (LLMs) are transforming software engineering, enabling autonomous agents capable of generating, repairing, and analysing code. Systems such as AutoCodeRover, SWE-agent, Copilot and RepairAgent showcase the potential of AI software engineers to boost productivity and accelerate development. Yet, a fundamental barrier persists: trustworthiness. Despite impressive performance on benchmarks, LLM-based software agents often produce untrustworthy results: they hallucinate, misinterpret vulnerabilities, and provide misleading explanations that obscure underlying reasoning. Studies reveal that these models frequently rely on spurious correlations and shortcut learning, mimicking surface patterns in training data rather than grasping true program semantics. This talk introduces a new approach of Trusted AI Agents for Software Engineering, aimed at restoring confidence in AI-assisted development. It presents the concept of trustworthiness oracles, which are automated evaluators that measure, explain, and audit both trustwrothiness. Integrating formal reasoning and interpretability, these oracles provide a foundation for measurable, explainable, and auditable trustworthiness in AI-generated artefacts.", bio: "Aldeida Aleti is a Professor in Software Engineering at Monash University, where her research spans the intersection of Software Engineering and Artificial Intelligence. Her work focuses on improving developer productivity through automation and advancing quality assurance methods for AI-based systems. She has contributed to areas such as automated software architecture optimisation, automated testing, and trustworthiness in AI-assisted software development." },
      { time: "10:00-10:20", duration: "20", type: "Talk", title: "Prompt Injection and Beyond: Advanced LLM Attack Vectors and Defenses", speaker: "Ben Kereopa-Yorke (NBN)", abstract: "Abstract placeholder - to be filled", bio: "Bio placeholder - to be filled" },
      { time: "10:20-10:30", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "10:30-11:00", duration: "30", type: "Break", title: "â˜• Break", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "The Future of Agentic Software Development", speaker: "", abstract: "", bio: "" },
      { time: "11:00-11:20", duration: "20", type: "Talk", title: "Rovo Dev: Toward Scaling AI Agents for Software Engineering", speaker: "Minwoo Jeong and Jirat Pasuksmit (Atlassian)", abstract: "AI agents for software engineering must operate reliably within large and diverse codebases. This talk centers on Atlassian's Rovo Dev and the architectural strategies behind scaling agentic systems in enterprise environments. We discuss approaches for balancing latency, cost, and accuracy, along with empirical insights on constraining agent behavior to maintain developer trust. We conclude with open challenges in evaluating agent workflows and managing data risks in proprietary software settings.", bio: "" },
      { time: "11:20-11:40", duration: "20", type: "Talk", title: "SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation", speaker: "Dr. Gopi Krishnan Rajbahadur (Huawei)", abstract: "High-quality labeled datasets are crucial for training and evaluating foundation models in software engineering, but creating them is often prohibitively expensive and labor-intensive. We introduce SPICE, a scalable, automated pipeline for labeling SWE-bench-style datasets with annotations for issue clarity, test coverage, and effort estimation. SPICE combines contextaware code navigation, rationale-driven prompting, and multipass consensus to produce labels that closely approximate expert annotations. SPICE's design was informed by our own experience and frustration in labeling more than 800 instances from SWEGym. SPICE achieves strong agreement with human-labeled SWE-bench Verified data while reducing the cost of labeling 1,000 instances from around $100,000 (manual annotation) to only $5.10. My talk will focus on the experience of building SPICE and how its being used in practice to improve the performance of Foundation Models on Software Engineering tasks.", bio: "Gopi Krishnan Rajbahadur is a Senior Staff Researcher at Huawei's Centre for Software Excellence in Canada, where he leads the data and post-training team for the Pangu Foundation Model to advance its software engineering capabilities. His research focuses on software engineering for AI-powered systems, requirements engineering for AIware, and the governance and compliance of AI datasets. He co-leads the AI and datasets profile in the ISO SPDX standard, co-organizes the International Workshop on Requirements Engineering for AI-powered Software (RAISE).\n\nGopi has extensive teaching and dissemination experience, including teaching a graduate course on Software Engineering and Foundation Models at Queen's University, co-organizing the AIware Bootcamp series (Toronto, Ottawa, Amsterdam), and delivering tutorials and technical briefings at ICSE, FSE, ASE, KDD, and CSER. He has also given invited lectures at institutions such as IIT Hyderabad, Kyushu University, Ã‰TS MontrÃ©al, and through the Linux Foundation's webinar series. His work has appeared in premier venues including TSE, TOSEM, EMSE, ASE, FSE, ICSE, and KDD." },
      { time: "11:40-12:00", duration: "20", type: "Talk", title: "LLMs' Efficacy for Code Generation and Software Improvement", speaker: "A/Prof Sherlock Licorish (Otago)", abstract: "Large Language Models (LLMs) have significantly advanced software engineering practices, particularly in automated code generation. However, the performance of LLMs in this domain is still the topic of global debate. Our work explores the effectiveness of LLMs when compared to human coders, optimal hyperparameter configurations and prompt designs for functional code generation, and LLMs' performance addressing broader dimensions of code quality (including security, reliability, readability, and maintainability). This talk will reflect on our outcomes and experiences, evaluating LLMs' efficacy for code generation and software improvement.", bio: "Sherlock A. Licorish is an Associate Professor in the School of Computing at University of Otago, New Zealand. He was awarded his PhD by Auckland University of Technology (AUT), and joined University of Otago in 2014. He explores the use of Artificial Intelligence (AI) in Software Engineering, including how to optimise the performance of Large Language Models (LLMs) and genetic improvement techniques for code generation, violation detection, and automated program repair." },
      { time: "12:00-12:10", duration: "10", type: "Spotlight", title: "CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models", speaker: "Hong Yi Lin (UniMelb)", abstract: "State-of-the-art large language models (LLMs) have demonstrated impressive code generation capabilities but struggle with real-world software engineering tasks, such as revising source code to address code reviews, hindering their practical use. Code review comments are often implicit, ambiguous, and colloquial, requiring models to grasp both code and human intent. This challenge calls for evaluating large language models' ability to bridge both technical and conversational contexts. While existing work has employed the automated code refinement (ACR) task to resolve these comments, current evaluation methods fall short, relying on text matching metrics that provide limited insight into model failures and remain susceptible to training data contamination. To address these limitations, we introduce a novel evaluation benchmark, CodeReviewQA that enables us to conduct fine-grained assessment of model capabilities and mitigate data contamination risks. In CodeReviewQA, we decompose the generation task of code refinement into three essential reasoning steps: change type recognition (CTR), change localisation (CL), and solution identification (SI). Each step is reformulated as multiple-choice questions with varied difficulty levels, enabling precise assessment of model capabilities, while mitigating data contamination risks. Our comprehensive evaluation spans 72 recently released large language models on 900 manually curated, high-quality examples across nine programming languages. Our results show that CodeReviewQA is able to expose specific model weaknesses in code review comprehension, disentangled from their generative automated code refinement results.", bio: "Hong Yi Lin is a PhD candidate in School of Computing and Information Systems (CIS) at The University of Melbourne, Australia." },
      { time: "12:10-12:20", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "12:20-13:20", duration: "60", type: "Lunch", title: "ðŸ½ï¸ Lunch", speaker: "", abstract: "", bio: "" },
      { time: "", duration: "", type: "Section", title: "Building and Managing Generative AI Software", speaker: "", abstract: "", bio: "" },
      { time: "13:20-13:40", duration: "20", type: "Talk", title: "Power Laws and Partnership: Rethinking SE Research in the Age of AI", speaker: "A/Prof Scott Barnett (Deakin)", abstract: "The software field is being upended by artificial intelligence just check SE blogs or papers published at ICSE! With much of the advances being made by teams in industry or motivated open-source communities what role do academics have in the future of SE? The way forward lies in studying the humble Power Law and the implications for industry collaboration. This talk will present a non-traditional approach to SE research and the benefits of working within the constraints of industry collaboration. Also presented will be a number of projects from Deakin's Applied AI Initiative and the lessons learned working across domains.", bio: "A/Prof Barnett's core work is on the design and implementation of robust AI centric applications. His approach for effectively using AI is centred on augmenting human workflows and designing systems that incrementally build towards a full AI solution. His work has helped organisations in the education, finance, healthcare, telecommunications, and manufacturing sectors. At the Applied Artificial Intelligence Institute, A/Prof Barnett leads the generative AI team that guides organisations on where and how to use generative AI, and the design and implementation of robust AI systems. A/Prof Barnett also founded and co-organises the GenAI Network in Melbourne that has +1100 members. This network enables practitioners to share insights and to build a community around safe and robust use of generative AI." },
      { time: "13:40-13:50", duration: "10", type: "Spotlight", title: "Redefining Software Project Management in the Era of Evolving AI", speaker: "Lakshana Assalaarachchi (Monash)", abstract: "Based on my PhD research and aligning with the OzSE 2026 aims to foster meaningful discussions on AI-embedded software engineering, I propose a spotlight talk on the title \"Redefining Software Project Management in the Era of Evolving AI\". The proposed spotlight talk will be based on findings from grey literature review (https://arxiv.org/abs/2510.10887) and preliminary findings from interview study (ongoing). I believe OzSE2026 is the ideal platform for me to discuss my preliminary research findings and get wider feedback from both researchers and practitioners who share the same interests in AI-embedded software engineering, to improve my research while benefiting the community. From a grey literature review of LinkedIn articles, blogs, and industry reports, I identified GenAI applications in software project management such as automation of routine tasks like document generation, predictive analytics, communication and meeting support, their benefits and concerns (https://arxiv.org/abs/2510.10887). Software project managers are encouraged to upskills in the GenAI era to get a competitive advantage in their career. Upskilling requirements in the GenAI era for project managers mapped to Project Management Institute's talent triangle were identified including prompt engineering, ethics and data security knowledge, human-AI collaborations, learning and adaptability, and emotional intelligence. I also identified practitioners' perspectives about Agentic SPM, where Agentic AI assistants manage software projects together with human project managers. I am currently interviewing software practitioners to fill the identified empirical research gaps in the areas of project manager's role transformation with evolving AI technologies, upskilling requirements, team members' perceptions towards project manager's AI usage, factors supporting adoption, and barriers to adoption of evolving AI technologies in software project management.", bio: "" },
      { time: "13:50-14:00", duration: "10", type: "Spotlight", title: "Challenges and Evolution in Reusing Pre-trained Models: Insights from Downstream Software Projects", speaker: "Peerachai Banyongrakkul (UniMelb)", abstract: "Pre-trained models (PTMs) enable developers to integrate powerful AI capabilities efficiently into their systems without building models from scratch, yet their reuse introduces unique and uncovered software engineering challenges. In this talk, I will first present key findings from our qualitative empirical study, published at ICSME 2025, which provides the first analysis of challenges developers face in open-source software projects reusing PTMs. Through systematic analysis of real-world issue reports, we identified recurring barriers related to model usage, model performance, software environment, computation resource, and documentation. A particularly novel challenge is the frequent request for additional model support and model replacement, driven by the rapid growth and continuous evolution of upstream model hubs. Building on these insights, the talk will transition to our ongoing mixed-method study that extends these findings to the evolutionary dimension, examining how PTMs actually change within software projects over time. This study aims to uncover patterns of model addition, migration, and removal throughout the projects' lifecycle. Together, these studies guide a broader understanding of PTM reuse and evolution in AI-driven software development, leading to more informed research and practice in this emerging area.", bio: "Peerachai Banyongrakkul is a PhD candidate in School of Computing and Information Systems (CIS) at The University of Melbourne, Australia. His research sits at the intersection of software engineering and artificial intelligence. He is particularly interested in leveraging data-driven techniques, including mining software repositories and software engineering analytics, to deeply explore the practical implications of reusing pre-trained models in modern software development." },
      { time: "14:00-14:10", duration: "10", type: "Q&A", title: "Joint Q&A Discussion", speaker: "Speakers", abstract: "", bio: "" },
      { time: "14:10-14:40", duration: "30", type: "Break", title: "â˜• Break", speaker: "", abstract: "", bio: "" },
      { time: "14:40-15:30", duration: "50", type: "Activity", title: "Opportunities & Challenges of Agentic SE (Interactive)", speaker: "Prof. Rashina Hoda (Monash) - Activity Lead", abstract: "Abstract placeholder - to be filled", bio: "Bio placeholder - to be filled" },
      { time: "15:30-17:00", duration: "90", type: "Event", title: "Networking/Social Event/Celebration + Closing", speaker: "OC Team", abstract: "", bio: "" },
    ]
  }
};

function Program({ id }) {
  const [selectedDay, setSelectedDay] = React.useState("day1");
  const [expandedRows, setExpandedRows] = React.useState(new Set());

  const toggleRow = (index) => {
    const newExpanded = new Set(expandedRows);
    if (newExpanded.has(index)) {
      newExpanded.delete(index);
    } else {
      newExpanded.add(index);
    }
    setExpandedRows(newExpanded);
  };

  const currentDay = programData[selectedDay];

  return (
    <div
      className="text-left p-12 space-y-8 px-4 sm:px-0 flex flex-col items-center justify-center"
      id={id}
    >
      <div className="flex flex-col pt-12 lg:px-0 md:px-4 space-y-8 sm:px-0 w-full max-w-6xl">
        <div className="flex flex-col pt-12 lg:px-0 md:px-4 space-y-8 sm:px-0">
          <h1 className="text-left text-3xl lg:px-0 md:px-4 sm:text-4xl font-bold">Program</h1>
        </div>

        {/* Day Selector */}
        <div className="flex gap-4 mb-6 justify-center flex-wrap">
          <button
            onClick={() => {
              setSelectedDay("day1");
              setExpandedRows(new Set());
            }}
            className={`rounded-full border-2 text-lg px-6 py-2 transition whitespace-nowrap ${
              selectedDay === "day1"
                ? "bg-[#000F46] text-white border-[#000F46]"
                : "border-[#000F46] text-[#000F46] hover:bg-[#000F46]/10"
            }`}
          >
            Day 1 - {programData.day1.date}
          </button>
          <button
            onClick={() => {
              setSelectedDay("day2");
              setExpandedRows(new Set());
            }}
            className={`rounded-full border-2 text-lg px-6 py-2 transition whitespace-nowrap ${
              selectedDay === "day2"
                ? "bg-[#000F46] text-white border-[#000F46]"
                : "border-[#000F46] text-[#000F46] hover:bg-[#000F46]/10"
            }`}
          >
            Day 2 - {programData.day2.date}
          </button>
        </div>

        {/* Table */}
        <div className="w-full overflow-x-auto">
          <table className="w-full border-collapse">
            <thead>
              <tr className="bg-gray-100 border-b-2 border-gray-300">
                <th className="text-left p-3 font-semibold text-sm md:text-base">Time</th>
                <th className="text-left p-3 font-semibold text-sm md:text-base">Duration</th>
                <th className="text-left p-3 font-semibold text-sm md:text-base">Title</th>
                <th className="text-left p-3 font-semibold text-sm md:text-base">Speaker</th>
              </tr>
            </thead>
            <tbody>
              {currentDay.sessions.map((session, index) => {
                const isExpanded = expandedRows.has(index);
                const hasDetails = session.abstract || session.bio;
                
                if (session.type === "Section") {
                  return (
                    <tr
                      key={index}
                      className="border-b border-gray-200 bg-slate-50"
                    >
                      <td colSpan="4" className="p-3 text-sm md:text-base font-bold text-slate-900">
                        â­ Section Title: {session.title}
                      </td>
                    </tr>
                  );
                }
                
                return (
                  <React.Fragment key={index}>
                    <tr
                      className={`border-b border-gray-200 transition-colors ${
                        index % 2 === 0 ? "bg-white" : "bg-gray-50"
                      } ${hasDetails ? "cursor-pointer hover:bg-blue-50" : ""} ${isExpanded ? "bg-blue-50" : ""}`}
                      onClick={() => hasDetails && toggleRow(index)}
                    >
                      <td className="p-3 text-sm md:text-base">
                        {session.time ? (
                          <span className="inline-block px-2 py-1 bg-blue-50 text-blue-700 rounded text-xs font-medium">
                            {session.time}
                          </span>
                        ) : (
                          <span className="text-gray-400">â€”</span>
                        )}
                      </td>
                      <td className="p-3 text-sm md:text-base">
                        {session.duration ? `${session.duration} min` : "â€”"}
                      </td>
                      <td className="p-3 text-sm md:text-base font-medium">
                        {session.title || "â€”"}
                        {hasDetails && (
                          <span className="ml-2 text-sm font-medium text-blue-600 hover:text-blue-800">
                            {isExpanded ? "â–¼" : "â–¶"} <span className="underline">{isExpanded ? "Hide details" : "View details"}</span>
                          </span>
                        )}
                      </td>
                      <td className="p-3 text-sm md:text-base text-gray-700">
                        {session.speaker || "â€”"}
                      </td>
                    </tr>
                    {isExpanded && hasDetails && (
                      <tr className="border-b border-gray-200 bg-blue-50">
                        <td colSpan="4" className="p-4">
                          <div className="space-y-4">
                            {session.abstract && (
                              <div>
                                <h4 className="font-semibold text-sm md:text-base mb-2 text-gray-900">ðŸ“„ Abstract</h4>
                                <p className="text-sm md:text-base text-gray-700 leading-relaxed">{session.abstract}</p>
                              </div>
                            )}
                            {session.bio && (
                              <div>
                                <h4 className="font-semibold text-sm md:text-base mb-2 text-gray-900">ðŸ‘¤ Bio</h4>
                                <p className="text-sm md:text-base text-gray-700 leading-relaxed">{session.bio}</p>
                              </div>
                            )}
                          </div>
                        </td>
                      </tr>
                    )}
                  </React.Fragment>
                );
              })}
            </tbody>
          </table>
        </div>
      </div>
    </div>
  );
}

export default Program;
